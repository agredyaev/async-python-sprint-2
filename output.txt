##filename:main.py#content_start:fromsrc.helpersimportrequires_python_versionfromsrc.core.loggerimportget_loggerfromsrc.core.settingsimportsettingsfromsrc.schemasimportTaskConfig,Pipelinefromsrc.task.factoryimportTaskFactoryfromsrc.task.poolimportTaskPoolfromsrc.schedulerimportSchedulerfromsrc.contextimportContextManagerfromsrc.stateimportFileStateManager@requires_python_version()defmain()->None:logger=get_logger(__name__)logger.info("Initializingtaskscheduler")#Initializecomponentstask_factory=TaskFactory()task_pool=TaskPool(settings.scheduler)context_manager=ContextManager()state_manager=FileStateManager(settings.scheduler.state_file_path)#Createschedulerscheduler=Scheduler(task_pool=task_pool,context_manager=context_manager,state_manager=state_manager,task_factory=task_factory,)#Example:Createandschedulesometasksfile_task=TaskConfig(task_type="FILE",task_specific_config={"operation":"READ","file_path":"/path/to/file.txt"})http_task=TaskConfig(task_type="HTTP",task_specific_config={"url":"https://api.example.com/data","method":"GET"})processing_task=TaskConfig(task_type="PROCESSING",task_specific_config={"processor_type":"data_analysis","input_data":{"key":"value"}})#Scheduleindividualtasksscheduler.schedule_task(file_task)scheduler.schedule_task(http_task)#Runtheschedulertry:logger.info("Startingscheduler")scheduler.run()exceptKeyboardInterrupt:logger.info("Stoppingscheduler")scheduler.stop()exceptExceptionase:logger.error(f"Anerroroccurred:{str(e)}")finally:logger.info("Schedulerstopped")if__name__=="__main__":main()content_end##filename:__init__.py#content_start:content_end##filename:core/logger.py#content_start:importloggingfromloggingimportconfigLOG_FORMAT="%(asctime)s-%(name)s-%(levelname)s-%(message)s"LOGGING={"version":1,"disable_existing_loggers":False,"formatters":{"verbose":{"format":LOG_FORMAT}},"handlers":{"console":{"class":"logging.StreamHandler","formatter":"verbose","level":"DEBUG","stream":"ext://sys.stdout",}},"root":{"handlers":["console"],"level":"INFO"},}defsetup_logging()->None:config.dictConfig(LOGGING)setup_logging()defget_logger(name:str)->logging.Logger:returnlogging.getLogger(name)content_end##filename:core/__init__.py#content_start:content_end##filename:core/settings.py#content_start:frompathlibimportPathfromsmtplibimportSMTPHeloErrorfromdotenvimportfind_dotenv,load_dotenvfrompydanticimportFieldfrompydantic_settingsimportBaseSettings,SettingsConfigDictload_dotenv(find_dotenv())classDefaultSettings(BaseSettings):"""Classtostoredefaultprojectsettings."""model_config=SettingsConfigDict(env_file=".env",env_file_encoding="utf-8",extra="ignore")classPythonVersionSettings(DefaultSettings):"""ClasstostorePythonversionsettings."""min_major:int=Field(...,description="Minimummajorversion")min_minor:int=Field(...,description="Minimumminorversion")model_config=SettingsConfigDict(env_prefix="PYTHON_VER_")classSchedulerConfig(DefaultSettings):"""Globalschedulerconfigurationparameters."""max_concurrent_tasks:int=Field(default=10,ge=1,description="Maximumconcurrenttasks")default_task_timeout:float=Field(default=60.0,ge=0,description="Defaulttasktimeoutinseconds")state_check_interval:float=Field(default=1.0,ge=0.1,description="Statecheckintervalinseconds")cleanup_interval:float=Field(default=3600.0,ge=0,description="Cleanupintervalinseconds")state_file_path:Path=Field(...,description="Statefilelocation")model_config=SettingsConfigDict(frozen=True,validate_assignment=True,env_prefix="SCHEDULER")classPipelineConfig(DefaultSettings):"""Configurationfortaskpipelineexecution."""max_parallel:int=Field(default=1,ge=1,description="Maximumparalleltasks")timeout:float=Field(default=3600.0,ge=0,description="Pipelinetimeoutinseconds")model_config=SettingsConfigDict(frozen=False,validate_assignment=True,env_prefix="PIPELINE")classSettings(BaseSettings):py_ver:PythonVersionSettings=PythonVersionSettings()scheduler:SchedulerConfig=SchedulerConfig()pipeline:PipelineConfig=PipelineConfig()settings=Settings()content_end##filename:core/exceptions.py#content_start:classBaseError(Exception):...classStateError(BaseError):"""Baseerrorforstateoperations."""...classStateFileError(StateError):"""Errorrelatedtostatefileoperations."""...classStateValidationError(StateError):"""Errorrelatedtostatevalidation."""...classContextError(BaseError):"""Baseerrorforcontextoperations."""...classContextNotFoundError(ContextError):"""Errorraisedwhencontextisnotfound."""...classContextValidationError(ContextError):"""Errorraisedwhencontextvalidationfails."""...classContextVersionError(ContextError):"""Errorraisedwhencontextversionconflictoccurs."""...classSchedulerError(BaseError):"""Baseexceptionforschedulererrors."""...classTaskPoolError(BaseError):"""Baseexceptionfortaskpoolerrors."""...classBaseTaskError(BaseError):"""Baseexceptionfortaskerrors."""...classTaskError(BaseTaskError):"""Baseexceptionfortaskerrors."""...classTaskCreationError(TaskError):"""Errorraisedwhentaskcreationfails."""...classTaskTypeNotFoundError(TaskError):"""Errorraisedwhentasktypeisnotregistered."""...classTaskConfigValidationError(TaskError):"""Errorraisedwhentaskconfigurationisinvalid."""...content_end##filename:helpers/__init__.py#content_start:fromsrc.helpers.check_python_versionimportrequires_python_versionfromsrc.helpers.get_json_dataimportfrom_json_filefromsrc.helpers.get_current_timestampimportget_current_timestamp__all__:list[str]=["requires_python_version","from_json_file","get_current_timestamp"]content_end##filename:helpers/get_json_data.py#content_start:fromtypingimportAnyfrompathlibimportPathfrompydantic_coreimportfrom_jsondeffrom_json_file(path:str)->dict[str,Any]:withPath(path).open("rb")asfile:returnfrom_json(file.read())content_end##filename:helpers/check_python_version.py#content_start:fromtypingimportAny,TypeVar,castimportsysfromcollections.abcimportCallablefromfunctoolsimportwrapsfromsrc.core.exceptionsimportUnsupportedPythonVersionErrorfromsrc.core.settingsimportsettingsF=TypeVar("F",bound=Callable[...,Any])defrequires_python_version()->Callable[[F],F]:min_major=settings.py_ver.min_majormin_minor=settings.py_ver.min_minordefdecorator(func:F)->F:@wraps(func)defwrapper(*args:Any,**kwargs:Any)->Any:ifsys.version_info.major<min_majoror(sys.version_info.major==min_majorandsys.version_info.minor<min_minor):raiseUnsupportedPythonVersionError(f"Requiredpythonversion>={min_major}.{min_minor}.")returnfunc(*args,**kwargs)returncast(F,wrapper)returndecoratorcontent_end##filename:helpers/get_current_timestamp.py#content_start:fromdatetimeimportUTC,datetimedefget_current_timestamp()->datetime:returndatetime.now(tz=UTC)content_end##filename:schemas/__init__.py#content_start:fromsrc.schemas.taskimportTaskConfig,TaskMetrics,FileOperation,FileTaskConfig,HttpTaskConfigfromsrc.schemas.conteximportContext,ContextMetadatafromsrc.schemas.enumsimportTaskState,TaskTypefromsrc.schemas.pipelineimportPipeline__all__:list[str]=["TaskConfig","Context","TaskState","TaskMetrics","TaskType","FileOperation","FileTaskConfig","HttpTaskConfig","Pipeline"]content_end##filename:schemas/contex.py#content_start:fromtypingimportAnyfromdatetimeimportdatetimefromuuidimportUUIDfrompydanticimportConfigDict,Fieldfromsrc.schemas.mixinsimportCreatedAtMixin,UpdatedAtMixin,UUIDMixinfromsrc.helpersimportget_current_timestampclassContextMetadata(CreatedAtMixin,UpdatedAtMixin):"""Metadatamodelforcontext."""version_history:list[dict[str,Any]]=Field(default_factory=list)pipeline_id:str|None=Noneassociated_tasks:list[str]=Field(default_factory=list)merged_from:str|None=Nonemerged_at:datetime|None=Nonesource_version:int|None=NoneclassContext(UUIDMixin,CreatedAtMixin,UpdatedAtMixin):"""Taskexecutioncontextcontainingruntimedataandresults."""pipeline_id:UUID|None=Field(None,description="Pipelineidentifieriftaskispartofpipeline")data:dict[str,Any]=Field(default_factory=dict,description="Contextdata")results:dict[str,Any]=Field(default_factory=dict,description="Executionresults")metadata:ContextMetadata=Field(default_factory=ContextMetadata,description="Contextmetadata")version:int=Field(default=1,ge=1,description="Contextversionnumber")model_config=ConfigDict(frozen=False,validate_assignment=True)defupdate_version(self)->None:"""Updatescontextversionandtimestamp."""self.version+=1self.updated_at=get_current_timestamp()content_end##filename:schemas/enums.py#content_start:fromenumimportIntEnum,StrEnum,autoclassTaskState(StrEnum):"""Availablestatesfortaskexecutionlifecycle."""CREATED=auto()PENDING=auto()RUNNING=auto()COMPLETED=auto()FAILED=auto()RETRY_PENDING=auto()classTaskType(StrEnum):"""Availabletasktypesinthesystem."""FILE=auto()HTTP=auto()classTaskPriority(IntEnum):"""Taskexecutionprioritylevels."""LOW=0MEDIUM=5HIGH=10CRITICAL=20classFileOperation(StrEnum):"""Availablefilesystemoperations."""CREATE=auto()READ=auto()WRITE=auto()DELETE=auto()APPEND=auto()classMetricType(StrEnum):"""Typesofmetricscollectedduringtaskexecution."""EXECUTION_TIME=auto()RETRY_COUNT=auto()ERROR_COUNT=auto()MEMORY_USAGE=auto()TASK_COUNT=auto()content_end##filename:schemas/pipeline.py#content_start:frompydanticimportConfigDict,Field,computed_field,model_validatorfromsrc.core.settingsimportsettingsfromsrc.schemas.mixinsimportUUIDMixinfromsrc.schemas.taskimportTaskConfigclassPipeline(UUIDMixin):"""Configurationfortaskpipelineexecution."""tasks:list[TaskConfig]=Field(...,min_length=1,description="Listofpipelinetasks")max_parallel:int=Field(settings.pipeline.max_parallel,description="Maximumparalleltasks")timeout:float=Field(settings.pipeline.timeout,description="Pipelinetimeoutinseconds")model_config=ConfigDict(frozen=False,validate_assignment=True)@computed_fielddeftask_count(self)->int:"""Returnsthetotalnumberoftasksinpipeline."""returnlen(self.tasks)@model_validator(mode="after")defvalidate_tasks(self)->"Pipeline":"""Validatestasklistisnotempty."""ifnotself.tasks:raiseValueError("Pipelinemustcontainatleastonetask")returnselfcontent_end##filename:schemas/mixins.py#content_start:fromdatetimeimportdatetimefromuuidimportUUID,uuid4frompydanticimportBaseModel,Fieldfromsrc.helpersimportget_current_timestampclassBaseMixin(BaseModel):model_config={"json_encoders":{datetime:lambdadt:dt.isoformat()}}classUUIDMixin(BaseMixin):id:UUID=Field(default_factory=uuid4,description="Uniqueidentifier")classCreatedAtMixin(BaseMixin):created_at:datetime=Field(default_factory=get_current_timestamp,description="Creationtime")classUpdatedAtMixin(BaseMixin):updated_at:datetime=Field(default_factory=get_current_timestamp,description="Updatetime")classStartedAtMixin(BaseMixin):started_at:datetime=Field(default_factory=get_current_timestamp,description="Executionstarttime")classCurrentTimestampMixin(BaseMixin):timestamp:datetime=Field(default_factory=get_current_timestamp,description="Measurementtime")content_end##filename:schemas/task.py#content_start:fromtypingimportAnyfromdatetimeimportUTC,datetimefromuuidimportUUIDfrompydanticimportBaseModel,ConfigDict,Field,model_validatorfromsrc.schemas.enumsimportFileOperation,TaskPriority,TaskTypefromsrc.schemas.mixinsimportCreatedAtMixin,UpdatedAtMixin,UUIDMixinclassTaskBase(BaseModel):model_config=ConfigDict(frozen=False,validate_assignment=True)classTaskMetrics(TaskBase,CreatedAtMixin,UpdatedAtMixin):"""Collectionofmetricsfortaskexecutionmonitoringandanalysis."""execution_time:float=Field(default=0.0,description="Executiontimeinseconds")retry_count:int=Field(default=0,description="Numberofretryattempts")error_count:int=Field(default=0,description="Numberoferrorsoccurred")memory_usage:float=Field(default=0.0,description="MemoryusageinMB")last_error:str|None=Field(default=None,description="Lasterrormessage")classTaskConfig(TaskBase,UUIDMixin):"""Baseconfigurationfortaskexecution."""task_type:TaskType=Field(...,description="Typeofthetask")priority:TaskPriority=Field(default=TaskPriority.MEDIUM,description="Taskexecutionpriority")dependencies:list[UUID]=Field(default_factory=list,description="ListofdependenttaskIDs")timeout:float=Field(default=60.0,ge=0,description="Executiontimeoutinseconds")max_retries:int=Field(default=0,ge=0,description="Maximumnumberofretryattempts")start_time:datetime|None=Field(default=None,description="Scheduledstarttime")task_specific_config:dict[str,Any]=Field(default_factory=dict,description="Task-specificconfiguration")@model_validator(mode="after")defvalidate_start_time(self)->"TaskConfig":"""Validatesthatstart_timeisnotinthepast."""ifself.start_timeandself.start_time<datetime.now(tz=UTC):raiseValueError("Starttimecannotbeinthepast")returnselfclassFileTaskConfig(TaskConfig):"""Configurationforfilesystemoperationtasks."""task_type:TaskType=Field(TaskType.FILE,frozen=True)operation:FileOperation=Field(...,description="Typeoffileoperation")file_path:str=Field(...,min_length=1,description="Targetfilepath")content:str|None=Field(None,description="Contentforwriteoperations")@model_validator(mode="after")defvalidate_content_required(self)->"FileTaskConfig":"""Validatescontentpresenceforwriteoperations."""ifself.operationin[FileOperation.WRITE,FileOperation.APPEND]andself.contentisNone:raiseValueError("Contentisrequiredforwriteandappendoperations")returnselfclassHttpTaskConfig(TaskConfig):"""ConfigurationforHTTPrequesttasks."""task_type:TaskType=Field(TaskType.HTTP,frozen=True)url:str=Field(...,description="TargetURLforHTTPrequest")method:str=Field(default="GET",description="HTTPmethod")headers:dict[str,str]=Field(default_factory=dict,description="HTTPheaders")timeout:float=Field(default=30.0,ge=0,description="HTTPrequesttimeout")content_end##filename:schemas/task_result.py#content_start:fromdatetimeimportdatetime,UTCfromtypingimportAnyfrompydanticimportBaseModel,Field,model_validator,ConfigDictfromuuidimportUUIDfromschemas.mixinsimportCreatedAtMixin,UpdatedAtMixinfromsrc.schemas.mixinsimportStartedAtMixin,CurrentTimestampMixinclassTaskResult(StartedAtMixin):"""Taskexecutionresultdata."""task_id:UUID=Field(...,description="Taskidentifier")success:bool=Field(True,description="Executionsuccessflag")result:Any|None=Field(None,description="Taskresultdata")error:str|None=Field(None,description="Errormessageiffailed")completed_at:datetime|None=Field(None,description="Executioncompletiontime")model_config=ConfigDict(frozen=False,validate_assignment=True)@propertydefexecution_time(self)->float|None:"""Returnsexecutiontimeinsecondsiftaskcompleted."""ifself.completed_atandself.started_at:return(self.completed_at-self.started_at).total_seconds()returnNoneclassResourceUsage(BaseModel):"""Resourceusagemetrics."""cpu_percent:float=Field(0.0,ge=0.0,le=100.0,description="CPUusagepercentage")memory_mb:float=Field(0.0,ge=0.0,description="Memoryusageinmegabytes")disk_reads:int=Field(0,ge=0,description="Numberofdiskreadoperations")disk_writes:int=Field(0,ge=0,description="Numberofdiskwriteoperations")network_rx_bytes:int=Field(0,ge=0,description="Bytesreceivedovernetwork")network_tx_bytes:int=Field(0,ge=0,description="Bytestransmittedovernetwork")model_config=ConfigDict(frozen=False,validate_assignment=True)classMetricRecord(CurrentTimestampMixin):"""Individualmetricmeasurement."""name:str=Field(...,min_length=1,description="Metricname")value:float=Field(...,description="Metricvalue")labels:dict[str,str]=Field(default_factory=dict,description="Metriclabels")model_config=ConfigDict(frozen=False,validate_assignment=True)classTaskMetrics(CreatedAtMixin,UpdatedAtMixin):"""Detailedtaskexecutionmetrics."""execution_time:float=Field(default=0.0,ge=0.0,description="Totalexecutiontimeinseconds")retry_count:int=Field(default=0,ge=0,description="Numberofretryattempts")error_count:int=Field(default=0,ge=0,description="Numberoferrorsoccurred")last_error:str|None=Field(None,description="Lasterrormessage")resource_usage:ResourceUsage=Field(...,description="Resourceusagemetrics")measurements:list[MetricRecord]=Field(default_factory=list,description="Detailedmetricmeasurements")model_config=ConfigDict(frozen=False,validate_assignment=True)defadd_measurement(self,name:str,value:float,labels:dict[str,str]|None=None)->None:"""Addnewmetricmeasurement."""self.measurements.append(MetricRecord(name=name,value=value,labels=labelsor{},timestamp=datetime.now(tz=UTC)))self.updated_at=datetime.now(tz=UTC)classRetryPolicy(BaseModel):"""Taskretrypolicyconfiguration."""max_retries:int=Field(default=60,ge=0,description="Maximumnumberofretryattempts")retry_delay:float=Field(default=1.0,ge=0.0,description="Delaybetweenretriesinseconds")max_delay:float=Field(default=300.0,ge=0.0,description="Maximumretrydelayinseconds")exponential_backoff:bool=Field(default=True,description="Useexponentialbackoffforretries")retry_on_exceptions:list[str]=Field(default_factory=list,description="Listofexceptionnamestoretryon")model_config=ConfigDict(frozen=True)defcalculate_delay(self,attempt:int)->float:"""Calculatedelayforgivenretryattempt."""ifnotself.exponential_backoff:returnself.retry_delaydelay=self.retry_delay*(2**(attempt-1))returnmin(delay,self.max_delay)classTaskTimeout(BaseModel):"""Tasktimeoutconfiguration."""total:float=Field(...,gt=0.0,description="Totalexecutiontimeoutinseconds")operation:float|None=Field(None,gt=0.0,description="Individualoperationtimeout")kill_on_timeout:bool=Field(True,description="Killtaskontimeout")model_config=ConfigDict(frozen=True)@model_validator(mode='after')defvalidate_timeouts(self)->'TaskTimeout':"""Validatethatoperationtimeoutdoesn'texceedtotaltimeout."""ifself.operationandself.operation>self.total:raiseValueError("Operationtimeoutcannotexceedtotaltimeout")returnselfclassExecutionPriority(BaseModel):"""Taskexecutionprioritysettings."""initial:int=Field(default=0,description="Initialtaskpriority")min_priority:int=Field(default=-100,description="Minimumpriorityvalue")max_priority:int=Field(default=100,description="Maximumpriorityvalue")age_boost:float=Field(default=0.0,description="Priorityboostpersecondofwaiting")retry_penalty:float=Field(default=0.0,description="Prioritypenaltyperretryattempt")model_config=ConfigDict(frozen=True)defcalculate_priority(self,wait_time:float,retry_count:int=0)->int:"""Calculatecurrentprioritybasedonwaittimeandretries."""priority=(self.initial+(wait_time*self.age_boost)-(retry_count*self.retry_penalty))returnmax(min(int(priority),self.max_priority),self.min_priority)content_end##filename:schemas/response.py#content_start:frompydanticimportBaseModelclassResponseData(BaseModel):status_code:intheaders:dict[str,str]content:strcontent_end##filename:task/__init__.py#content_start:content_end##filename:task/factory.py#content_start:fromtypingimportfinalfromcollections.abcimportMappingfromthreadingimportRLockfrompydanticimportBaseModel,ValidationErrorfromsrc.core.exceptionsimportTaskConfigValidationError,TaskCreationError,TaskTypeNotFoundErrorfromsrc.protocolsimportTaskFactoryProtocol,TaskProtocolfromsrc.schemasimportFileTaskConfig,HttpTaskConfig,TaskConfig,TaskTypefromsrc.task.fileimportFileTaskfromsrc.task.httpimportHttpTaskclassTaskTypeConfig(BaseModel):task_class:type[TaskProtocol]config_class:type[TaskConfig]@finalclassTaskFactory(TaskFactoryProtocol):"""Factoryforcreatingtaskinstancesbasedonconfiguration."""def__init__(self)->None:"""Initializetaskfactorywithdefaulttasktypes."""self._task_types:dict[TaskType,TaskTypeConfig]={}self._lock=RLock()self._register_default_tasks()def_register_default_tasks(self)->None:"""Registerdefaulttaskimplementations."""self.register_task_type(TaskType.FILE,FileTask,FileTaskConfig)self.register_task_type(TaskType.HTTP,HttpTask,HttpTaskConfig)defregister_task_type(self,task_type:TaskType,task_class:type[TaskProtocol],config_class:type[TaskConfig])->None:"""Registernewtasktypewithitsimplementationclass.Args:task_type:Typeofthetasktask_class:Taskimplementationclassconfig_class:ConfigurationclassforthetaskRaises:ValueError:Iftask_type,task_classorconfig_classisinvalid"""ifnotisinstance(task_type,TaskType):raiseValueError(f"TasktypemustbeinstanceofTaskTypeenum,got{type(task_type)}")ifnotisinstance(task_class,type)ornotissubclass(task_class,TaskProtocol):raiseValueError(f"TaskclassmustbeasubclassofTaskProtocol,got{task_class}")ifnotisinstance(config_class,type)ornotissubclass(config_class,TaskConfig):raiseValueError(f"ConfigclassmustbeasubclassofTaskConfig,got{config_class}")withself._lock:self._task_types[task_type]=TaskTypeConfig(task_class=task_class,config_class=config_class)defcreate_task(self,config:TaskConfig)->TaskProtocol:"""Createtaskinstancebasedonconfiguration.Args:config:TaskconfigurationReturns:CreatedtaskinstanceRaises:TaskCreationError:Iftaskcreationfails"""try:returnself._create_task_internal(config)except(TaskTypeNotFoundError,TaskConfigValidationError,ValidationError)ase:raiseTaskCreationError(f"Failedtocreatetask:{e!s}")fromedef_create_task_internal(self,config:TaskConfig)->TaskProtocol:"""Internalmethodfortaskcreationwithpropertypechecking.Args:config:TaskconfigurationReturns:CreatedtaskinstanceRaises:TaskTypeNotFoundError:IftasktypeisnotregisteredTaskConfigValidationError:Ifconfigurationisinvalid"""ifnotisinstance(config.task_type,TaskType):raiseTaskConfigValidationError(f"Invalidtasktype:{config.task_type}.MustbeinstanceofTaskTypeenum.")withself._lock:task_type_config=self._task_types.get(config.task_type)iftask_type_configisNone:raiseTaskTypeNotFoundError(f"Tasktype{config.task_type}isnotregistered")ifnotisinstance(config,task_type_config.config_class):raiseTaskConfigValidationError(f"Invalidconfigurationtypefor{config.task_type}."f"Expected{task_type_config.config_class.__name__},got{type(config).__name__}")returntask_type_config.task_class(config)defunregister_task_type(self,task_type:TaskType)->None:"""Removetasktyperegistration.Args:task_type:TypeoftasktounregisterRaises:ValueError:Iftask_typeisnotvalid"""ifnotisinstance(task_type,TaskType):raiseValueError(f"TasktypemustbeinstanceofTaskTypeenum,got{type(task_type)}")withself._lock:self._task_types.pop(task_type,None)defget_registered_types(self)->list[TaskType]:"""Getlistofregisteredtasktypes.Returns:Listofregisteredtasktypes"""withself._lock:returnlist(self._task_types.keys())defget_task_config(self)->Mapping[TaskType,type[TaskConfig]]:"""Getmappingoftasktypestotheirconfigurationclasses.Returns:Mappingoftasktypestoconfigurationclasses"""withself._lock:return{task_type:config.config_classfortask_type,configinself._task_types.items()}content_end##filename:task/pool.py#content_start:importheapqfromcollectionsimportdefaultdictfromcollections.abcimportGeneratorfromdataclassesimportdataclass,fieldfromdatetimeimportdatetimefromthreadingimportRLockfromuuidimportUUIDfrompydanticimportBaseModel,Fieldfromsrc.core.exceptionsimportTaskPoolErrorfromsrc.core.settingsimportsettingsfromsrc.protocolsimportTaskPoolProtocol,TaskProtocolfromsrc.schemasimportTaskStateclassExecutionPriority(BaseModel):"""Modelforcalculatingtaskexecutionpriority."""base_priority:int=Field(default=0,ge=0)wait_time_weight:float=Field(default=0.1,ge=0)retry_weight:float=Field(default=5,ge=0)defcalculate_priority(self,wait_time:float,retry_count:int)->float:"""Calculateprioritybasedonwaittimeandretrycount."""returnself.base_priority+(wait_time*self.wait_time_weight)+(retry_count*self.retry_weight)@dataclass(order=True)classPrioritizedTask:"""Taskwrapperwithpriorityqueuesupport."""priority:floatadded_time:datetime=field(compare=False)task:TaskProtocol=field(compare=False)execution_priority:ExecutionPriority=field(compare=False,default_factory=ExecutionPriority)def__post_init__(self)->None:"""Initializewithinvertedpriorityformin-heap."""self.priority=-self.prioritydefrecalculate_priority(self)->None:"""Recalculatetaskprioritybasedonwaittimeandretries."""wait_time=(datetime.now()-self.added_time).total_seconds()retry_count=getattr(self.task.metrics,"retry_count",0)self.priority=-self.execution_priority.calculate_priority(wait_time=wait_time,retry_count=retry_count)classTaskPool(TaskPoolProtocol):"""Implementationoftaskpoolwithpriority-basedscheduling."""def__init__(self)->None:self._config=settings.schedulerself._lock=RLock()self._pending_tasks:list[PrioritizedTask]=[]self._running_tasks:dict[UUID,TaskProtocol]={}self._completed_tasks:dict[UUID,TaskProtocol]={}self._failed_tasks:dict[UUID,TaskProtocol]={}self._task_dependencies:defaultdict[UUID,set[UUID]]=defaultdict(set)self._dependent_tasks:defaultdict[UUID,set[UUID]]=defaultdict(set)self._task_added_times:dict[UUID,datetime]={}self._task_priorities:dict[UUID,ExecutionPriority]={}defadd_task(self,task:TaskProtocol)->Generator[None,None,None]:ifnottask:raiseTaskPoolError("TaskcannotbeNone")task_id=task.task_idwithself._lock:yieldfromself._check_task_exists(task_id)iftask.dependencies:self._task_dependencies[task_id].update(task.dependencies)fordep_idintask.dependencies:self._dependent_tasks[dep_id].add(task_id)prioritized_task=PrioritizedTask(priority=task.priority,added_time=datetime.now(),task=task,execution_priority=ExecutionPriority())heapq.heappush(self._pending_tasks,prioritized_task)self._task_added_times[task_id]=prioritized_task.added_timeself._task_priorities[task_id]=prioritized_task.execution_prioritytask.set_state(TaskState.PENDING)yielddefget_next_task(self)->Generator[None,None,TaskProtocol|None]:withself._lock:iflen(self._running_tasks)>=self._config.max_concurrent_tasks:yieldreturnNoneavailable_tasks:list[PrioritizedTask]=[]task_to_run=Nonewhileself._pending_tasks:prioritized_task=heapq.heappop(self._pending_tasks)prioritized_task.recalculate_priority()if(yieldfromself._can_execute_task(prioritized_task.task)):task_to_run=prioritized_task.taskbreakelse:available_tasks.append(prioritized_task)fortaskinavailable_tasks:heapq.heappush(self._pending_tasks,task)iftask_to_run:self._running_tasks[task_to_run.task_id]=task_to_runtask_to_run.set_state(TaskState.RUNNING)yieldreturntask_to_rundefremove_task(self,task_id:UUID)->Generator[None,None,None]:withself._lock:task=self._running_tasks.pop(task_id,None)iftask:iftask.get_state()==TaskState.COMPLETED:self._completed_tasks[task_id]=taskelse:self._failed_tasks[task_id]=taskfordependent_idinself._dependent_tasks.pop(task_id,set()):self._task_dependencies[dependent_id].discard(task_id)self._task_added_times.pop(task_id,None)self._task_priorities.pop(task_id,None)yieldreturnraiseTaskPoolError(f"Task{task_id}notfoundinrunningtasks")defget_running_tasks(self)->Generator[None,None,list[TaskProtocol]]:withself._lock:yieldreturnlist(self._running_tasks.values())defget_pending_tasks(self)->Generator[None,None,list[TaskProtocol]]:withself._lock:yieldreturn[pt.taskforptinself._pending_tasks]def_check_task_exists(self,task_id:UUID)->Generator[None,None,None]:iftask_idinself._running_tasksortask_idinself._completed_tasksor\task_idinself._failed_tasksortask_idinself._task_added_times:raiseTaskPoolError(f"Task{task_id}alreadyexistsinthepool")yielddef_can_execute_task(self,task:TaskProtocol)->Generator[None,None,bool]:task_deps=self._task_dependencies.get(task.task_id,set())ifnottask_deps:yieldreturnTruefordep_idintask_deps:ifdep_idnotinself._completed_tasks:yieldreturnFalseyieldreturnTruedefcleanup_completed(self,older_than:datetime)->Generator[None,None,None]:withself._lock:fortask_dictin(self._completed_tasks,self._failed_tasks):to_remove=[task_idfortask_id,taskintask_dict.items()iftask.metrics.updated_at<=older_than]fortask_idinto_remove:task_dict.pop(task_id)yielddefget_task_counts(self)->dict[TaskState,int]:withself._lock:return{TaskState.PENDING:len(self._pending_tasks),TaskState.RUNNING:len(self._running_tasks),TaskState.COMPLETED:len(self._completed_tasks),TaskState.FAILED:len(self._failed_tasks)}defget_task_wait_time(self,task_id:UUID)->float|None:added_time=self._task_added_times.get(task_id)ifadded_time:return(datetime.now()-added_time).total_seconds()returnNonecontent_end##filename:task/base.py#content_start:fromtypingimportClassVarfromabcimportABC,abstractmethodfromcollections.abcimportGeneratorfromdatetimeimportdatetimefromuuidimportUUIDfrompydanticimportBaseModelfromsrc.helpersimportget_current_timestampfromsrc.schemasimportContext,TaskConfig,TaskMetrics,TaskStatefromsrc.core.exceptionsimportBaseTaskErrorclassTaskError(BaseModel):message:strtimestamp:datetimeclassBaseTask(ABC):"""Baseimplementationoftaskfunctionality."""DEFAULT_STATE:ClassVar[TaskState]=TaskState.CREATEDdef__init__(self,config:TaskConfig)->None:"""Initializebasetaskparameters."""self._config:TaskConfig=configself._state:TaskState=self.DEFAULT_STATEself._metrics:TaskMetrics=TaskMetrics()self._start_time:datetime|None=Noneself._end_time:datetime|None=Noneself._error:TaskError|None=None@propertydeftask_id(self)->UUID:"""Gettaskuniqueidentifier."""returnself._config.id@propertydefpriority(self)->int:"""Gettaskpriority."""returnself._config.priority.value@propertydefdependencies(self)->list[UUID]:"""Gettaskdependencies."""returnself._config.dependencies@propertydefmetrics(self)->TaskMetrics:"""Gettaskexecutionmetrics."""returnself._metricsdefget_state(self)->TaskState:"""Getcurrenttaskstate."""returnself._statedefset_state(self,state:TaskState)->None:"""Setnewtaskstate."""self._state=statedefexecute(self,context:Context)->Generator[None,None,None]:"""Executetaskwithprovidedcontext.Args:context:TaskexecutioncontextReturns:GeneratoryieldingNoneoneachexecutionstep"""try:self._start_execution()yieldfromself._do_execute(context)self._complete_execution()exceptBaseTaskErrorase:self._handle_error(e)raise@abstractmethoddef_do_execute(self,context:Context)->Generator[None,None,None]:"""Implementactualtaskexecutionlogic.Args:context:TaskexecutioncontextReturns:GeneratoryieldingNoneoneachexecutionstep"""yielddef_start_execution(self)->None:"""Preparetaskforexecution."""self._start_time=get_current_timestamp()self._state=TaskState.RUNNINGself._update_metrics()def_complete_execution(self)->None:"""Handlesuccessfultaskcompletion."""self._end_time=get_current_timestamp()self._state=TaskState.COMPLETEDself._update_metrics()def_handle_error(self,error:Exception)->None:"""Handletaskexecutionerror."""self._error=TaskError(message=str(error),timestamp=get_current_timestamp())self._end_time=get_current_timestamp()self._state=TaskState.FAILEDself._metrics.error_count+=1self._metrics.last_error=str(error)self._update_metrics()def_update_metrics(self)->None:"""Updatetaskmetrics."""self._metrics.updated_at=get_current_timestamp()ifself._start_time:self._metrics.execution_time=(get_current_timestamp()-self._start_time).total_seconds()content_end##filename:task/file.py#content_start:fromcollections.abcimportCallable,GeneratorfrompathlibimportPathfromsrc.core.exceptionsimportTaskErrorfromsrc.schemasimportContext,FileOperation,FileTaskConfigfromsrc.task.baseimportBaseTasktypePathStr=strtypeOperationFunc=Callable[[PathStr,Context],Generator[None,None,None]]classFileTask(BaseTask):"""Implementationoffilesystemoperationstask."""def__init__(self,config:FileTaskConfig)->None:"""Initializefiletask.Args:config:Filetaskconfiguration"""super().__init__(config)self._config:FileTaskConfig=configself._operations:dict[FileOperation,OperationFunc]={FileOperation.READ:self._read_file,FileOperation.WRITE:self._write_file,FileOperation.APPEND:self._append_file,FileOperation.DELETE:self._delete_file,FileOperation.CREATE:self._create_file,}def_do_execute(self,context:Context)->Generator[None,None,None]:"""Executefileoperationbasedonconfiguration.Args:context:Taskexecutioncontext"""operation=self._config.operationpath=self._config.file_pathtry:operation_func=self._operations.get(operation)ifoperation_func:yieldfromoperation_func(path,context)context.data["file_path"]=pathcontext.data["operation"]=operation.valueexceptTaskErrorase:context.data["error"]=str(e)raisedef_read_file(self,path:PathStr,context:Context)->Generator[None,None,None]:withPath(path).open()asf:content=f.read()yieldcontext.results[str(self.task_id)]=contentdef_write_file(self,path:PathStr)->Generator[None,None,None]:yieldwithPath(path).open("w")asf:f.write(self._config.contentor"")yielddef_append_file(self,path:PathStr)->Generator[None,None,None]:yieldwithPath(path).open("a")asf:f.write(self._config.contentor"")yield@staticmethoddef_delete_file(path:PathStr)->Generator[None,None,None]:ifPath(path).exists():yieldPath(path).unlink()yielddef_create_file(self,path:PathStr)->Generator[None,None,None]:ifnotPath(path).exists():yieldwithPath(path).open("w")asf:ifself._config.content:f.write(self._config.content)yieldcontent_end##filename:task/http.py#content_start:fromcollections.abcimportGeneratorimportrequestsfromsrc.schemasimportContext,HttpTaskConfigfromsrc.schemas.responseimportResponseDatafromsrc.task.baseimportBaseTaskclassHttpTask(BaseTask):"""ImplementationofHTTPrequesttask."""def__init__(self,config:HttpTaskConfig)->None:"""InitializeHTTPtask.Args:config:HTTPtaskconfiguration"""super().__init__(config)self._config:HttpTaskConfig=configdef_do_execute(self,context:Context)->Generator[None,None,None]:"""ExecuteHTTPrequestbasedonconfiguration.Args:context:Taskexecutioncontext"""yield#Yieldbeforerequesttoallowinterruptionwithrequests.Session()assession:yield#Aftersessioncreationtry:response=self._make_request(session)yield#Afterrequestresponse.raise_for_status()yield#Afterraise_for_statusself._store_results(context,response)exceptrequests.RequestExceptionase:context.data["error"]=str(e)raiseyield#Finalyieldaftersessioniscloseddef_make_request(self,session:requests.Session)->requests.Response:"""MaketheHTTPrequest."""returnsession.request(method=self._config.method,url=self._config.url,headers=self._config.headers,timeout=self._config.timeout)def_store_results(self,context:Context,response:requests.Response)->None:"""StoretheresultsoftheHTTPrequestinthecontext."""context.results[str(self.task_id)]=ResponseData(status_code=response.status_code,headers=dict(response.headers),content=response.text).model_dump()context.data["url"]=self._config.urlcontext.data["method"]=self._config.methodcontent_end##filename:protocols/__init__.py#content_start:fromsrc.protocols.contex_managerimportContextManagerProtocolfromsrc.protocols.state_managerimportStateManagerProtocolfromsrc.protocols.taskimportTaskProtocolfromsrc.protocols.task_factoryimportTaskFactoryProtocolfromsrc.protocols.task_poolimportTaskPoolProtocol__all__:list[str]=["StateManagerProtocol","ContextManagerProtocol","TaskProtocol","TaskPoolProtocol","TaskFactoryProtocol",]content_end##filename:protocols/task.py#content_start:fromtypingimportProtocol,runtime_checkablefromcollections.abcimportGeneratorfromdatetimeimportdatetimefromuuidimportUUIDfromsrc.schemasimportContext,TaskConfig,TaskMetrics,TaskState@runtime_checkableclassTaskProtocol(Protocol):"""Protocoldefiningtheinterfaceforalltasktypes."""@propertydeftask_id(self)->UUID:"""Returnsuniquetaskidentifier."""...@propertydefpriority(self)->int:"""Returnstaskpriority."""...@propertydefdependencies(self)->list[UUID]:"""ReturnslistofdependenttaskIDs."""...@propertydefmetrics(self)->TaskMetrics:"""Returnstaskexecutionmetrics."""...defexecute(self,context:Context)->Generator[None,None,None]:"""Executesthetaskwithgivencontext.Args:context:TaskexecutioncontextReturns:GeneratoryieldingNoneoneachexecutionstep"""...defget_state(self)->TaskState:"""Returnscurrenttaskstate."""...defset_state(self,state:TaskState)->None:"""Updatestaskstate."""...@runtime_checkableclassTaskFactoryProtocol(Protocol):"""Protocolfortaskfactoryimplementation."""defcreate_task(self,config:TaskConfig)->Generator[None,None,TaskProtocol]:"""Createstaskinstancebasedonconfiguration.Args:config:TaskconfigurationReturns:Generatoryieldingcreatedtaskinstance"""...@runtime_checkableclassContextManagerProtocol(Protocol):"""Protocolforcontextmanagementoperations."""defcreate_context(self,pipeline_id:UUID|None=None)->Generator[None,None,Context]:"""Createsnewexecutioncontext.Args:pipeline_id:OptionalpipelineidentifierReturns:Generatoryieldingcreatedcontext"""...defget_context(self,task_id:UUID)->Generator[None,None,Context]:"""RetrievescontextbytaskID.Args:task_id:TaskidentifierReturns:Generatoryieldingtaskcontext"""...defupdate_context(self,context:Context)->Generator[None,None,None]:"""Updatesexistingcontext.Args:context:ContexttoupdateReturns:GeneratoryieldingNoneoneachupdatestep"""...defcleanup_context(self,pipeline_id:UUID)->Generator[None,None,None]:"""RemovescontextbypipelineID.Args:pipeline_id:PipelineidentifierReturns:GeneratoryieldingNoneoneachcleanupstep"""...defmerge_contexts(self,source:Context,target:Context)->Generator[None,None,Context]:"""Mergessourcecontextintotargetcontext.Args:source:Sourcecontexttarget:TargetcontextReturns:Generatoryieldingmergedcontext"""...defassociate_task(self,task_id:UUID,context_id:UUID)->Generator[None,None,None]:"""Associatestaskwithcontext.Args:task_id:Taskidentifiercontext_id:ContextidentifierReturns:GeneratoryieldingNoneoncompletion"""...@runtime_checkableclassStateManagerProtocol(Protocol):"""Protocolformanagingschedulerandtaskstates."""defsave_state(self)->Generator[None,None,None]:"""Persistscurrentstatetostorage.Returns:GeneratoryieldingNoneoneachsavestep"""...defload_state(self)->Generator[None,None,None]:"""Loadsstatefromstorage.Returns:GeneratoryieldingNoneoneachloadstep"""...defupdate_task_state(self,task_id:UUID,state:TaskState)->Generator[None,None,None]:"""Updatestaskstate.Args:task_id:Taskidentifierstate:NewtaskstateReturns:GeneratoryieldingNoneoncompletion"""...defget_task_state(self,task_id:UUID)->Generator[None,None,TaskState]:"""Retrievestaskstate.Args:task_id:TaskidentifierReturns:Generatoryieldingtaskstate"""...defcleanup_states(self,older_than:datetime)->Generator[None,None,None]:"""Removesoldstaterecords.Args:older_than:TimestampforcleanupReturns:GeneratoryieldingNoneoneachcleanupstep"""...@runtime_checkableclassTaskPoolProtocol(Protocol):"""Protocolfortaskpoolmanagement."""defadd_task(self,task:TaskProtocol)->Generator[None,None,None]:"""Addstasktothepool.Args:task:TasktoaddReturns:GeneratoryieldingNoneoncompletion"""...defget_next_task(self)->Generator[None,None,TaskProtocol|None]:"""Returnsnexttaskforexecution.Returns:GeneratoryieldingnexttaskorNone"""...defremove_task(self,task_id:UUID)->Generator[None,None,None]:"""Removestaskfrompool.Args:task_id:TaskidentifierReturns:GeneratoryieldingNoneoncompletion"""...defget_running_tasks(self)->Generator[None,None,list[TaskProtocol]]:"""Returnslistofcurrentlyrunningtasks.Returns:Generatoryieldinglistofrunningtasks"""...defget_pending_tasks(self)->Generator[None,None,list[TaskProtocol]]:"""Returnslistofpendingtasks.Returns:Generatoryieldinglistofpendingtasks"""...content_end##filename:protocols/task_pool.py#content_start:fromtypingimportProtocol,runtime_checkablefromcollections.abcimportGeneratorfromdatetimeimportdatetimefromuuidimportUUIDfromsrc.schemasimportContext,TaskConfig,TaskMetrics,TaskState@runtime_checkableclassTaskProtocol(Protocol):"""Protocoldefiningtheinterfaceforalltasktypes."""@propertydeftask_id(self)->UUID:"""Returnsuniquetaskidentifier."""...@propertydefpriority(self)->int:"""Returnstaskpriority."""...@propertydefdependencies(self)->list[UUID]:"""ReturnslistofdependenttaskIDs."""...@propertydefmetrics(self)->TaskMetrics:"""Returnstaskexecutionmetrics."""...defexecute(self,context:Context)->Generator[None,None,None]:"""Executesthetaskwithgivencontext.Args:context:TaskexecutioncontextReturns:GeneratoryieldingNoneoneachexecutionstep"""...defget_state(self)->TaskState:"""Returnscurrenttaskstate."""...defset_state(self,state:TaskState)->None:"""Updatestaskstate."""...@runtime_checkableclassTaskFactoryProtocol(Protocol):"""Protocolfortaskfactoryimplementation."""defcreate_task(self,config:TaskConfig)->Generator[None,None,TaskProtocol]:"""Createstaskinstancebasedonconfiguration.Args:config:TaskconfigurationReturns:Generatoryieldingcreatedtaskinstance"""...@runtime_checkableclassContextManagerProtocol(Protocol):"""Protocolforcontextmanagementoperations."""defcreate_context(self,pipeline_id:UUID|None=None)->Generator[None,None,Context]:"""Createsnewexecutioncontext.Args:pipeline_id:OptionalpipelineidentifierReturns:Generatoryieldingcreatedcontext"""...defget_context(self,task_id:UUID)->Generator[None,None,Context]:"""RetrievescontextbytaskID.Args:task_id:TaskidentifierReturns:Generatoryieldingtaskcontext"""...defupdate_context(self,context:Context)->Generator[None,None,None]:"""Updatesexistingcontext.Args:context:ContexttoupdateReturns:GeneratoryieldingNoneoneachupdatestep"""...defcleanup_context(self,pipeline_id:UUID)->Generator[None,None,None]:"""RemovescontextbypipelineID.Args:pipeline_id:PipelineidentifierReturns:GeneratoryieldingNoneoneachcleanupstep"""...defmerge_contexts(self,source:Context,target:Context)->Generator[None,None,Context]:"""Mergessourcecontextintotargetcontext.Args:source:Sourcecontexttarget:TargetcontextReturns:Generatoryieldingmergedcontext"""...defassociate_task(self,task_id:UUID,context_id:UUID)->Generator[None,None,None]:"""Associatestaskwithcontext.Args:task_id:Taskidentifiercontext_id:ContextidentifierReturns:GeneratoryieldingNoneoncompletion"""...@runtime_checkableclassStateManagerProtocol(Protocol):"""Protocolformanagingschedulerandtaskstates."""defsave_state(self)->Generator[None,None,None]:"""Persistscurrentstatetostorage.Returns:GeneratoryieldingNoneoneachsavestep"""...defload_state(self)->Generator[None,None,None]:"""Loadsstatefromstorage.Returns:GeneratoryieldingNoneoneachloadstep"""...defupdate_task_state(self,task_id:UUID,state:TaskState)->Generator[None,None,None]:"""Updatestaskstate.Args:task_id:Taskidentifierstate:NewtaskstateReturns:GeneratoryieldingNoneoncompletion"""...defget_task_state(self,task_id:UUID)->Generator[None,None,TaskState]:"""Retrievestaskstate.Args:task_id:TaskidentifierReturns:Generatoryieldingtaskstate"""...defcleanup_states(self,older_than:datetime)->Generator[None,None,None]:"""Removesoldstaterecords.Args:older_than:TimestampforcleanupReturns:GeneratoryieldingNoneoneachcleanupstep"""...@runtime_checkableclassTaskPoolProtocol(Protocol):"""Protocolfortaskpoolmanagement."""defadd_task(self,task:TaskProtocol)->Generator[None,None,None]:"""Addstasktothepool.Args:task:TasktoaddReturns:GeneratoryieldingNoneoncompletion"""...defget_next_task(self)->Generator[None,None,TaskProtocol|None]:"""Returnsnexttaskforexecution.Returns:GeneratoryieldingnexttaskorNone"""...defremove_task(self,task_id:UUID)->Generator[None,None,None]:"""Removestaskfrompool.Args:task_id:TaskidentifierReturns:GeneratoryieldingNoneoncompletion"""...defget_running_tasks(self)->Generator[None,None,list[TaskProtocol]]:"""Returnslistofcurrentlyrunningtasks.Returns:Generatoryieldinglistofrunningtasks"""...defget_pending_tasks(self)->Generator[None,None,list[TaskProtocol]]:"""Returnslistofpendingtasks.Returns:Generatoryieldinglistofpendingtasks"""...content_end##filename:protocols/task_factory.py#content_start:fromtypingimportProtocol,runtime_checkablefromcollections.abcimportGeneratorfromdatetimeimportdatetimefromuuidimportUUIDfromsrc.schemasimportContext,TaskConfig,TaskMetrics,TaskState@runtime_checkableclassTaskProtocol(Protocol):"""Protocoldefiningtheinterfaceforalltasktypes."""@propertydeftask_id(self)->UUID:"""Returnsuniquetaskidentifier."""...@propertydefpriority(self)->int:"""Returnstaskpriority."""...@propertydefdependencies(self)->list[UUID]:"""ReturnslistofdependenttaskIDs."""...@propertydefmetrics(self)->TaskMetrics:"""Returnstaskexecutionmetrics."""...defexecute(self,context:Context)->Generator[None,None,None]:"""Executesthetaskwithgivencontext.Args:context:TaskexecutioncontextReturns:GeneratoryieldingNoneoneachexecutionstep"""...defget_state(self)->TaskState:"""Returnscurrenttaskstate."""...defset_state(self,state:TaskState)->None:"""Updatestaskstate."""...@runtime_checkableclassTaskFactoryProtocol(Protocol):"""Protocolfortaskfactoryimplementation."""defcreate_task(self,config:TaskConfig)->Generator[None,None,TaskProtocol]:"""Createstaskinstancebasedonconfiguration.Args:config:TaskconfigurationReturns:Generatoryieldingcreatedtaskinstance"""...@runtime_checkableclassContextManagerProtocol(Protocol):"""Protocolforcontextmanagementoperations."""defcreate_context(self,pipeline_id:UUID|None=None)->Generator[None,None,Context]:"""Createsnewexecutioncontext.Args:pipeline_id:OptionalpipelineidentifierReturns:Generatoryieldingcreatedcontext"""...defget_context(self,task_id:UUID)->Generator[None,None,Context]:"""RetrievescontextbytaskID.Args:task_id:TaskidentifierReturns:Generatoryieldingtaskcontext"""...defupdate_context(self,context:Context)->Generator[None,None,None]:"""Updatesexistingcontext.Args:context:ContexttoupdateReturns:GeneratoryieldingNoneoneachupdatestep"""...defcleanup_context(self,pipeline_id:UUID)->Generator[None,None,None]:"""RemovescontextbypipelineID.Args:pipeline_id:PipelineidentifierReturns:GeneratoryieldingNoneoneachcleanupstep"""...defmerge_contexts(self,source:Context,target:Context)->Generator[None,None,Context]:"""Mergessourcecontextintotargetcontext.Args:source:Sourcecontexttarget:TargetcontextReturns:Generatoryieldingmergedcontext"""...defassociate_task(self,task_id:UUID,context_id:UUID)->Generator[None,None,None]:"""Associatestaskwithcontext.Args:task_id:Taskidentifiercontext_id:ContextidentifierReturns:GeneratoryieldingNoneoncompletion"""...@runtime_checkableclassStateManagerProtocol(Protocol):"""Protocolformanagingschedulerandtaskstates."""defsave_state(self)->Generator[None,None,None]:"""Persistscurrentstatetostorage.Returns:GeneratoryieldingNoneoneachsavestep"""...defload_state(self)->Generator[None,None,None]:"""Loadsstatefromstorage.Returns:GeneratoryieldingNoneoneachloadstep"""...defupdate_task_state(self,task_id:UUID,state:TaskState)->Generator[None,None,None]:"""Updatestaskstate.Args:task_id:Taskidentifierstate:NewtaskstateReturns:GeneratoryieldingNoneoncompletion"""...defget_task_state(self,task_id:UUID)->Generator[None,None,TaskState]:"""Retrievestaskstate.Args:task_id:TaskidentifierReturns:Generatoryieldingtaskstate"""...defcleanup_states(self,older_than:datetime)->Generator[None,None,None]:"""Removesoldstaterecords.Args:older_than:TimestampforcleanupReturns:GeneratoryieldingNoneoneachcleanupstep"""...@runtime_checkableclassTaskPoolProtocol(Protocol):"""Protocolfortaskpoolmanagement."""defadd_task(self,task:TaskProtocol)->Generator[None,None,None]:"""Addstasktothepool.Args:task:TasktoaddReturns:GeneratoryieldingNoneoncompletion"""...defget_next_task(self)->Generator[None,None,TaskProtocol|None]:"""Returnsnexttaskforexecution.Returns:GeneratoryieldingnexttaskorNone"""...defremove_task(self,task_id:UUID)->Generator[None,None,None]:"""Removestaskfrompool.Args:task_id:TaskidentifierReturns:GeneratoryieldingNoneoncompletion"""...defget_running_tasks(self)->Generator[None,None,list[TaskProtocol]]:"""Returnslistofcurrentlyrunningtasks.Returns:Generatoryieldinglistofrunningtasks"""...defget_pending_tasks(self)->Generator[None,None,list[TaskProtocol]]:"""Returnslistofpendingtasks.Returns:Generatoryieldinglistofpendingtasks"""...content_end##filename:protocols/contex_manager.py#content_start:fromtypingimportProtocol,runtime_checkablefromcollections.abcimportGeneratorfromuuidimportUUIDfromsrc.schemasimportContext@runtime_checkableclassContextManagerProtocol(Protocol):"""Protocoldefiningcontextmanagementinterface."""defcreate_context(self,pipeline_id:UUID|None=None)->Generator[None,None,Context]:...defget_context(self,task_id:UUID)->Generator[None,None,Context]:...defupdate_context(self,context:Context)->Generator[None,None,None]:...defcleanup_context(self,pipeline_id:UUID)->Generator[None,None,None]:...defmerge_contexts(self,source:Context,target:Context)->Generator[None,None,Context]:...defassociate_task(self,task_id:UUID,context_id:UUID)->Generator[None,None,None]:...content_end##filename:protocols/state_manager.py#content_start:fromtypingimportProtocol,runtime_checkablefromcollections.abcimportGeneratorfromdatetimeimportdatetimefromuuidimportUUIDfromsrc.schemasimportTaskState@runtime_checkableclassStateManagerProtocol(Protocol):defsave_state(self)->Generator[None,None,None]:...defload_state(self)->Generator[None,None,None]:...defupdate_task_state(self,task_id:UUID,state:TaskState)->Generator[None,None,None]:...defget_task_state(self,task_id:UUID)->Generator[None,None,TaskState]:...defcleanup_states(self,older_than:datetime)->Generator[None,None,None]:...content_end##filename:scheduler/__init__.py#content_start:fromsrc.scheduler.managerimportSchedulercontent_end##filename:scheduler/manager.py#content_start:fromtypingimportGeneratorfromthreadingimportRLockfromuuidimportUUIDimporttimefromdatetimeimportdatetime,timedeltafromcollectionsimportdequefrompydanticimportBaseModelfromsrc.core.settingsimportsettingsfromsrc.schemasimportTaskState,TaskConfig,Pipelinefromsrc.protocolsimport(TaskPoolProtocol,ContextManagerProtocol,StateManagerProtocol,TaskFactoryProtocol,TaskProtocol)fromsrc.core.exceptionsimportSchedulerErrorclassSchedulerStatus(BaseModel):is_running:boolactive_coroutines:intlast_maintenance:datetimeclassScheduler:"""Mainschedulerimplementationusingcoroutinesfortaskexecution."""def__init__(self,task_pool:TaskPoolProtocol,context_manager:ContextManagerProtocol,state_manager:StateManagerProtocol,task_factory:TaskFactoryProtocol,)->None:self._task_pool=task_poolself._context_manager=context_managerself._state_manager=state_managerself._task_factory=task_factoryself._config=settings.schedulerself._lock=RLock()self._status=SchedulerStatus(is_running=False,active_coroutines=0,last_maintenance=datetime.now())self._active_coroutines:deque[Generator]=deque()defscheduler_loop(self)->Generator[None,None,None]:"""Mainschedulercoroutine."""whileself._status.is_running:try:task=yieldfromself._task_pool.get_next_task()iftask:task_coroutine=self._process_task(task)self._active_coroutines.append(task_coroutine)yieldself._process_coroutines()exceptExceptionase:print(f"Errorinschedulerloop:{str(e)}")yielddef_process_coroutines(self)->None:"""Processactivecoroutines."""for_inrange(min(len(self._active_coroutines),self._config.max_concurrent_tasks)):ifnotself._active_coroutines:breakcoroutine=self._active_coroutines.popleft()try:next(coroutine)self._active_coroutines.append(coroutine)exceptStopIteration:passexceptExceptionase:print(f"Errorincoroutine:{str(e)}")def_process_task(self,task:TaskProtocol)->Generator[None,None,None]:"""Processsingletaskasacoroutine."""try:context=self._context_manager.get_context(task.task_id)yieldfromtask.execute(context)self._context_manager.update_context(context)self._state_manager.update_task_state(task.task_id,TaskState.COMPLETED)exceptExceptionase:context.data['error']=str(e)self._context_manager.update_context(context)self._state_manager.update_task_state(task.task_id,TaskState.FAILED)finally:yieldfromself._task_pool.remove_task(task.task_id)defmaintenance_loop(self)->Generator[None,None,None]:"""Maintenancecoroutine."""whileself._status.is_running:try:current_time=datetime.now()ifcurrent_time-self._status.last_maintenance>timedelta(seconds=self._config.cleanup_interval):yieldfromself._run_maintenance(current_time)self._status.last_maintenance=current_timeyieldexceptExceptionase:print(f"Errorinmaintenanceloop:{str(e)}")yielddef_run_maintenance(self,current_time:datetime)->Generator[None,None,None]:"""Runmaintenanceoperationsasacoroutine."""cleanup_time=current_time-timedelta(seconds=self._config.cleanup_interval)try:yieldfromself._state_manager.cleanup_states(cleanup_time)yieldfromself._task_pool.cleanup_completed(cleanup_time)yieldfromself._state_manager.save_state()exceptExceptionase:print(f"Errorduringmaintenance:{str(e)}")defrun(self)->None:"""Runschedulerusingcoroutines."""withself._lock:ifself._status.is_running:raiseSchedulerError("Schedulerisalreadyrunning")self._status.is_running=Truetry:self._state_manager.load_state()scheduler_gen=self.scheduler_loop()maintenance_gen=self.maintenance_loop()whileself._status.is_running:next(scheduler_gen)next(maintenance_gen)time.sleep(self._config.state_check_interval)exceptExceptionase:raiseSchedulerError(f"Schedulererror:{str(e)}")fromefinally:self._status.is_running=Falsedefstop(self)->None:"""Stopscheduleroperationgracefully."""withself._lock:self._status.is_running=Falseself._state_manager.save_state()defschedule_task(self,config:TaskConfig)->Generator[None,None,UUID]:"""Schedulesingletaskforexecution."""try:task=self._task_factory.create_task(config)yieldcontext=self._context_manager.create_context()self._context_manager.associate_task(task.task_id,context.context_id)yieldyieldfromself._task_pool.add_task(task)self._state_manager.update_task_state(task.task_id,TaskState.PENDING)yieldreturntask.task_idexceptExceptionase:raiseSchedulerError(f"Failedtoscheduletask:{str(e)}")fromedefschedule_pipeline(self,config:Pipeline)->Generator[None,None,UUID]:"""Schedulepipelineoftasksforexecution."""try:pipeline_context=self._context_manager.create_context(config.pipeline_id)yieldfortask_configinconfig.tasks:task=self._task_factory.create_task(task_config)yieldself._context_manager.associate_task(task.task_id,pipeline_context.context_id)yieldyieldfromself._task_pool.add_task(task)self._state_manager.update_task_state(task.task_id,TaskState.PENDING)yieldreturnconfig.pipeline_idexceptExceptionase:raiseSchedulerError(f"Failedtoschedulepipeline:{str(e)}")fromedefget_task_status(self,task_id:UUID)->dict:"""Getcurrenttaskstatus."""try:state=self._state_manager.get_task_state(task_id)context=self._context_manager.get_context(task_id)return{'task_id':task_id,'state':state.value,'results':context.results.get(str(task_id)),'error':context.data.get('error'),'updated_at':context.updated_at.isoformat()}exceptExceptionase:raiseSchedulerError(f"Failedtogettaskstatus:{str(e)}")fromedefget_pipeline_status(self,pipeline_id:UUID)->dict:"""Getpipelinestatus."""try:context=self._context_manager.get_pipeline_context(pipeline_id)return{'pipeline_id':pipeline_id,'tasks':context.results,'error':context.data.get('error'),'updated_at':context.updated_at.isoformat()}exceptExceptionase:raiseSchedulerError(f"Failedtogetpipelinestatus:{str(e)}")fromecontent_end##filename:state/__init__.py#content_start:fromsrc.state.managerimportFileStateManagercontent_end##filename:state/manager.py#content_start:fromfunctoolsimportlru_cachefromtypingimportGenerator,SetfromthreadingimportRLockfromdatetimeimportdatetimefromuuidimportUUIDimportjsonimportosfrompathlibimportPathimportfcntlimporttimefromcontextlibimportcontextmanagerfromhelpersimportget_current_timestampfromsrc.schemasimportTaskStatefromcore.settingsimportsettingsfromsrc.protocolsimportStateManagerProtocolfromsrc.core.exceptionsimportStateFileError,StateError,StateValidationErrorclassFileStateManager(StateManagerProtocol):def__init__(self)->None:self._config=settings.schedulerself._lock=RLock()self._states:dict[UUID,TaskState]={}self._modified_states:Set[UUID]=set()self._state_file=settings.scheduler.state_file_pathself._lock_file=self._state_file.with_suffix('.lock')self._last_save_time:datetime|None=Noneself._state_cache=lru_cache(maxsize=100)(self._get_state_from_storage)@contextmanagerdef_file_lock(self,timeout:float=10.0)->Generator[int,None,None]:lock_fd=Nonestart_time=time.monotonic()try:whileTrue:try:ifnotself._lock_file.exists():self._lock_file.touch()lock_fd=os.open(str(self._lock_file),os.O_RDWR)fcntl.flock(lock_fd,fcntl.LOCK_EX|fcntl.LOCK_NB)breakexcept(IOError,OSError)ase:iftime.monotonic()-start_time>timeout:raiseStateFileError(f"Failedtoacquirefilelockafter{timeout}seconds")frometime.sleep(0.1)yieldlock_fdfinally:iflock_fdisnotNone:try:fcntl.flock(lock_fd,fcntl.LOCK_UN)os.close(lock_fd)except(IOError,OSError):passdef_get_state_from_storage(self,task_id:UUID)->TaskState|None:returnself._states.get(task_id)defsave_state(self)->Generator[None,None,None]:ifnotself._modified_states:yieldreturntry:withself._lock:state_data={'version':1,'timestamp':get_current_timestamp().isoformat(),'states':{str(task_id):state.valuefortask_id,stateinself._states.items()}}yieldyieldfromself._create_backup()withself._file_lock()as_:temp_file=self._state_file.with_suffix('.tmp')withopen(temp_file,'w')asf:json.dump(state_data,f,indent=2)yieldtemp_file.replace(self._state_file)yieldwithself._lock:self._modified_states.clear()self._last_save_time=get_current_timestamp()exceptExceptionase:raiseStateFileError(f"Failedtosavestate:{str(e)}")fromedefload_state(self)->Generator[None,None,None]:ifnotself._state_file.exists():yieldreturntry:withself._file_lock()as_:yieldfromself._validate_state_file()withopen(self._state_file,'r')asf:state_data=json.load(f)yieldwithself._lock:self._states={UUID(task_id):TaskState(value=state)fortask_id,stateinstate_data.get('states',{}).items()}self._modified_states.clear()yieldexceptjson.JSONDecodeErrorase:raiseStateFileError(f"Invalidstatefileformat:{str(e)}")fromeexceptExceptionase:raiseStateFileError(f"Failedtoloadstate:{str(e)}")fromedefupdate_task_state(self,task_id:UUID,state:TaskState)->Generator[None,None,None]:ifnotisinstance(state,TaskState):raiseStateValidationError(f"Invalidstatetype:{type(state)}")withself._lock:current_state=self._states.get(task_id)ifcurrent_state!=state:self._states[task_id]=stateself._modified_states.add(task_id)self._state_cache.cache_clear()yieldif(self._last_save_timeisNoneor(get_current_timestamp()-self._last_save_time).total_seconds()>self._config.state_check_interval):yieldfromself.save_state()defget_task_state(self,task_id:UUID)->Generator[None,None,TaskState]:state=self._state_cache(task_id)ifstateisNone:raiseStateError(f"Statenotfoundfortask{task_id}")yieldreturnstatedefcleanup_states(self,older_than:datetime)->Generator[None,None,None]:yieldfromself._cleanup_memory_states(older_than)yieldfromself._cleanup_backup_files(older_than)def_cleanup_memory_states(self,older_than:datetime)->Generator[None,None,None]:withself._lock:yielddef_cleanup_backup_files(self,older_than:datetime)->Generator[None,None,None]:try:backup_pattern=self._state_file.with_suffix('.bak.*')forbackup_fileinPath(self._state_file.parent).glob(str(backup_pattern)):try:timestamp_str=backup_file.suffix[1:]file_time=datetime.strptime(timestamp_str,"%Y%m%d_%H%M%S")iffile_time<older_than:backup_file.unlink()yieldexcept(ValueError,OSError):continueexceptExceptionase:print(f"Errorcleaningupbackupfiles:{str(e)}")yielddef_create_backup(self)->Generator[None,None,None]:ifself._state_file.exists():try:backup_file=self._state_file.with_suffix(f'.bak.{get_current_timestamp().strftime("%Y%m%d_%H%M%S")}')importshutilshutil.copy2(self._state_file,backup_file)yieldexceptExceptionase:print(f"Warning:Failedtocreatestatefilebackup:{str(e)}")yielddef_validate_state_file(self)->Generator[None,None,None]:try:withopen(self._state_file,'r')asf:state_data=json.load(f)yieldrequired_fields={'version','timestamp','states'}ifnotall(fieldinstate_dataforfieldinrequired_fields):raiseStateFileError("Invalidstatefile:missingrequiredfields")yieldifstate_data['version']!=1:raiseStateFileError(f"Unsupportedstatefileversion:{state_data['version']}")yieldtry:datetime.fromisoformat(state_data['timestamp'])exceptValueErrorase:raiseStateFileError("Invalidtimestampformat")fromeyieldexceptjson.JSONDecodeErrorase:raiseStateFileError(f"Invalidstatefileformat:{str(e)}")fromeexceptExceptionase:raiseStateFileError(f"Failedtovalidatestatefile:{str(e)}")fromedefget_modified_task_ids(self)->Set[UUID]:withself._lock:returnset(self._modified_states)defhas_modified_states(self)->bool:returnbool(self._modified_states)defget_all_states(self)->dict[UUID,TaskState]:withself._lock:returndict(self._states)content_end##filename:context/__init__.py#content_start:fromsrc.context.managerimportContextManagercontent_end##filename:context/manager.py#content_start:fromtypingimportAnyfromcollections.abcimportGeneratorfromdatetimeimportUTC,datetimefromthreadingimportRLockfromuuidimportUUIDfromhelpersimportget_current_timestampfromsrc.protocolsimportContextManagerProtocolfromsrc.schemasimportContextfromsrc.core.exceptionsimportContextNotFoundError,ContextVersionErrorclassContextManager(ContextManagerProtocol):"""Implementationofcontextmanagementfunctionality."""def__init__(self)->None:self._lock=RLock()self._contexts:dict[UUID,Context]={}self._task_contexts:dict[UUID,UUID]={}self._pipeline_contexts:dict[UUID,UUID]={}self._context_versions:dict[UUID,int]={}self._shared_data:dict[str,Any]={}defcreate_context(self,pipeline_id:UUID|None=None)->Generator[None,None,Context]:"""Createnewexecutioncontext."""context=Context(pipeline_id=pipeline_id)withself._lock:self._contexts[context.id]=contextself._context_versions[context.id]=1ifpipeline_id:self._pipeline_contexts[pipeline_id]=context.idcontext.metadata.pipeline_id=str(pipeline_id)yieldreturncontext.model_copy(deep=True)defget_context(self,task_id:UUID)->Generator[None,None,Context]:"""GetcontextbytaskID."""withself._lock:context_id=self._task_contexts.get(task_id)ifnotcontext_id:raiseContextNotFoundError(f"Contextnotfoundfortask{task_id}")context=self._contexts.get(context_id)ifnotcontext:raiseContextNotFoundError(f"Context{context_id}notfound")yieldreturncontext.model_copy(deep=True)defupdate_context(self,context:Context)->Generator[None,None,None]:"""Updateexistingcontext."""withself._lock:existing=self._contexts.get(context.id)ifnotexisting:raiseContextNotFoundError(f"Context{context.id}notfound")current_version=self._context_versions.get(context.id,0)ifcontext.version<=current_version:raiseContextVersionError(f"Versionconflict.Current:{current_version},Provided:{context.version}")self._record_changes(existing,context)self._contexts[context.id]=contextself._context_versions[context.id]=context.versionyielddefcleanup_context(self,pipeline_id:UUID)->Generator[None,None,None]:"""RemovecontextbypipelineID."""withself._lock:context_id=self._pipeline_contexts.get(pipeline_id)ifnotcontext_id:raiseContextNotFoundError(f"Contextnotfoundforpipeline{pipeline_id}")self._cleanup_context_by_id(context_id)self._pipeline_contexts.pop(pipeline_id)task_ids=[task_idfortask_id,ctx_idinself._task_contexts.items()ifctx_id==context_id]fortask_idintask_ids:self._task_contexts.pop(task_id)yielddefmerge_contexts(self,source:Context,target:Context)->Generator[None,None,Context]:"""Mergesourcecontextintotargetcontext."""withself._lock:new_context=target.model_copy(deep=True)new_context.version+=1new_context.updated_at=datetime.now(UTC)#Mergedataandresultsnew_context.data.update(source.data)new_context.results.update(source.results)#Updatemetadatanew_context.metadata.merged_from=str(source.id)new_context.metadata.merged_at=get_current_timestamp()new_context.metadata.source_version=source.versionself._contexts[new_context.id]=new_contextself._context_versions[new_context.id]=new_context.versionyieldreturnnew_context.model_copy(deep=True)defassociate_task(self,task_id:UUID,context_id:UUID)->Generator[None,None,None]:"""Associatetaskwithcontext."""withself._lock:ifcontext_idnotinself._contexts:raiseContextNotFoundError(f"Context{context_id}notfound")self._task_contexts[task_id]=context_idself._contexts[context_id].metadata.associated_tasks.append(str(task_id))yielddef_cleanup_context_by_id(self,context_id:UUID)->None:"""Cleanupcontextandrelateddata."""self._contexts.pop(context_id,None)self._context_versions.pop(context_id,None)def_record_changes(self,old_context:Context,new_context:Context)->None:"""Recordchangesbetweencontextversions."""changes={"version":self._context_versions[old_context.id],"timestamp":datetime.now(UTC),"changes":{"data":self._diff_dicts(old_context.data,new_context.data),"results":self._diff_dicts(old_context.results,new_context.results),"metadata":self._diff_dicts(old_context.metadata.model_dump(exclude={"version_history"}),new_context.metadata.model_dump(exclude={"version_history"}))}}new_context.metadata.version_history.append(changes)new_context.updated_at=get_current_timestamp()def_diff_dicts(self,old:dict,new:dict,exclude:set[str]|None=None)->dict:"""Comparedictionariesandreturnchanges."""exclude=excludeorset()changes={"added":{},"modified":{},"removed":{}}forkey,valueinnew.items():ifkeyinexclude:continueifkeynotinold:changes["added"][key]=valueelifold[key]!=value:changes["modified"][key]={"old":old[key],"new":value}changes["removed"]={k:vfork,vinold.items()ifknotinnewandknotinexclude}returnchangescontent_end